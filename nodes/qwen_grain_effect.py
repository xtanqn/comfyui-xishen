import torch
import numpy as np
from PIL import Image
from nodes import MAX_RESOLUTION

# å®šä¹‰èŠ‚ç‚¹ç±»ï¼Œç”¨äºç»™å›¾åƒæ·»åŠ ç”µå½±é¢—ç²’æ•ˆæœ
class Qwen_Image_Grain_Effect:
    """
    ä¸ºå›¾åƒæ·»åŠ ç”µå½±é¢—ç²’æ•ˆæœï¼Œæ¨¡æ‹Ÿèƒ¶ç‰‡æ‘„å½±çš„é¢—ç²’è´¨æ„Ÿ
    """
    # å®šä¹‰èŠ‚ç‚¹åˆ†ç±»
    CATEGORY = "ğŸ¡Comfyui-xishen"
    # å®šä¹‰èŠ‚ç‚¹åç§°
    NAME = "ğŸ‰Image-é¢—ç²’è´¨æ„Ÿ"
    # å®šä¹‰èŠ‚ç‚¹æè¿°
    DESCRIPTION = "ä¸ºå›¾åƒæ·»åŠ ç”µå½±é¢—ç²’æ•ˆæœï¼Œæ¨¡æ‹Ÿèƒ¶ç‰‡æ‘„å½±çš„é¢—ç²’è´¨æ„Ÿ"

    @classmethod
    def INPUT_TYPES(cls):
        """
        å®šä¹‰èŠ‚ç‚¹çš„è¾“å…¥å‚æ•°
        """
        return {
            "required": {
                "image": ("IMAGE",),  # è¾“å…¥å›¾åƒ
                "é¢—ç²’å°ºå¯¸": ("FLOAT", {
                    "default": 0.6,       # é»˜è®¤å€¼
                    "min": 0.25,          # æœ€å°å€¼
                    "max": 2.0,           # æœ€å¤§å€¼
                    "step": 0.05,         # è°ƒèŠ‚æ­¥é•¿
                    "display": "slider"   # æ»‘å—æ˜¾ç¤º
                }),
                "é¢—ç²’å¼ºåº¦": ("FLOAT", {
                    "default": 0.5,       # é»˜è®¤å€¼
                    "min": 0.0,           # æœ€å°å€¼
                    "max": 10.0,          # æœ€å¤§å€¼
                    "step": 0.05,         # è°ƒèŠ‚æ­¥é•¿
                    "display": "slider"   # æ»‘å—æ˜¾ç¤º
                }),
                "é¢—ç²’é¥±å’Œåº¦": ("FLOAT", {
                    "default": 0.7,       # é»˜è®¤å€¼
                    "min": 0.0,           # æœ€å°å€¼
                    "max": 2.0,           # æœ€å¤§å€¼
                    "step": 0.05,         # è°ƒèŠ‚æ­¥é•¿
                    "display": "slider"   # æ»‘å—æ˜¾ç¤º
                }),
                "æš—éƒ¨é¢—ç²’": ("FLOAT", {
                    "default": 0.0,       # é»˜è®¤å€¼
                    "min": 0.0,           # æœ€å°å€¼
                    "max": 0.5,           # æœ€å¤§å€¼
                    "step": 0.01,         # è°ƒèŠ‚æ­¥é•¿
                    "display": "slider"   # æ»‘å—æ˜¾ç¤º
                }),
                "seed": ("INT", {
                    "default": 0,          # é»˜è®¤å€¼
                    "min": 0,              # æœ€å°å€¼
                    "step": 1,             # è°ƒèŠ‚æ­¥é•¿
                }),
            },
        }

    # å®šä¹‰è¾“å‡ºç±»å‹
    RETURN_TYPES = ("IMAGE",)
    # å®šä¹‰è¾“å‡ºåç§°
    RETURN_NAMES = ("IMAGE",)
    # å®šä¹‰èŠ‚ç‚¹æ‰§è¡Œçš„å‡½æ•°
    FUNCTION = "add_grain_effect"

    def add_grain_effect(self, image, é¢—ç²’å°ºå¯¸, é¢—ç²’å¼ºåº¦, é¢—ç²’é¥±å’Œåº¦, æš—éƒ¨é¢—ç²’, seed):
        """
        ä¸ºå›¾åƒæ·»åŠ ç”µå½±é¢—ç²’æ•ˆæœ
        
        å‚æ•°:
            image: è¾“å…¥å›¾åƒå¼ é‡
            é¢—ç²’å°ºå¯¸: é¢—ç²’çš„å¤§å°ï¼Œ0.25-2ï¼Œæ•°å€¼è¶Šå¤§é¢—ç²’è¶Šç²—
            é¢—ç²’å¼ºåº¦: é¢—ç²’çš„æ˜æ˜¾ç¨‹åº¦ï¼Œ0-10ï¼Œæ•°å€¼è¶Šé«˜é¢—ç²’æ„Ÿè¶Šå¼º
            é¢—ç²’é¥±å’Œåº¦: é¢—ç²’çš„è‰²å½©é¥±å’Œåº¦ï¼Œ0-2ï¼Œæ•°å€¼è¶Šé«˜è‰²å½©è¶Šé²œè‰³
            æš—éƒ¨é¢—ç²’: æš—éƒ¨åŒºåŸŸçš„é¢—ç²’æ§åˆ¶ï¼Œ0-0.5ï¼Œå€¼ä¸º0æ—¶ä¸åšé¢å¤–è°ƒæ•´
            seed: éšæœºç§å­
        
        è¿”å›:
            å¤„ç†åçš„å›¾åƒå¼ é‡
        """
        # è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿é¢—ç²’æ•ˆæœå¯å¤ç°
        np.random.seed(seed)
        torch.manual_seed(seed)
        
        # å°†å›¾åƒè½¬æ¢ä¸ºnumpyæ•°ç»„å¤„ç†
        # åŸå§‹å›¾åƒå½¢çŠ¶: (batch_size, height, width, channels)
        batch_size, height, width, channels = image.shape
        
        # åˆå§‹åŒ–è¾“å‡ºåˆ—è¡¨
        result_images = []
        
        # éå†æ¯ä¸ªå›¾åƒè¿›è¡Œå¤„ç†
        for b in range(batch_size):
            # è·å–å•ä¸ªå›¾åƒ
            img = image[b].numpy()
            
            # è°ƒæ•´å›¾åƒèŒƒå›´åˆ°[0, 1]
            img = np.clip(img, 0, 1)
            
            # è®¡ç®—é¢—ç²’å¤§å°ï¼ˆåŸºäºå›¾åƒå°ºå¯¸å’Œé¢—ç²’å°ºå¯¸å‚æ•°ï¼‰
            grain_size = max(1, int(é¢—ç²’å°ºå¯¸ * 2))
            
            # åˆ›å»ºéšæœºå™ªå£°ï¼ˆé¢—ç²’ï¼‰
            # ç”ŸæˆåŸºç¡€å™ªå£°
            noise = np.random.rand(height, width, channels)
            
            # æ ¹æ®é¢—ç²’å°ºå¯¸è°ƒæ•´å™ªå£°
            if grain_size > 1:
                # å¯¹å™ªå£°è¿›è¡Œä¸‹é‡‡æ ·å’Œä¸Šé‡‡æ ·ï¼Œæ¨¡æ‹Ÿä¸åŒå¤§å°çš„é¢—ç²’
                from scipy.ndimage import zoom
                noise = zoom(noise, (grain_size, grain_size, 1), order=0)
                noise = zoom(noise, (1/grain_size, 1/grain_size, 1), order=0)
            
            # è°ƒæ•´å™ªå£°åˆ°åˆé€‚çš„èŒƒå›´
            noise = (noise - 0.5) * 2  # è°ƒæ•´åˆ°[-1, 1]èŒƒå›´
            
            # è®¡ç®—æš—éƒ¨å¢å¼ºå› å­
            # å¯¹äºæš—éƒ¨åŒºåŸŸï¼ˆåƒç´ å€¼ä½çš„åŒºåŸŸï¼‰ï¼Œå¢å¼ºé¢—ç²’æ•ˆæœ
            # é¦–å…ˆè®¡ç®—å›¾åƒçš„äº®åº¦åˆ†é‡
            luminance = np.dot(img[..., :3], [0.299, 0.587, 0.114])
            # è®¡ç®—æš—éƒ¨å› å­ï¼Œäº®åº¦è¶Šä½ï¼Œå› å­è¶Šå¤§
            dark_factor = 1.0 + (1.0 - luminance) * æš—éƒ¨é¢—ç²’ * 2.0
            
            # å°†æš—éƒ¨å› å­æ‰©å±•åˆ°3é€šé“
            dark_factor = np.repeat(dark_factor[:, :, np.newaxis], channels, axis=2)
            
            # åº”ç”¨æš—éƒ¨å› å­åˆ°å™ªå£°
            noise = noise * dark_factor
            
            # è°ƒæ•´é¢—ç²’é¥±å’Œåº¦
            # å¦‚æœé¥±å’Œåº¦ä¸º0ï¼Œå°†å™ªå£°è½¬æ¢ä¸ºç°åº¦
            if é¢—ç²’é¥±å’Œåº¦ == 0:
                noise_gray = np.dot(noise[..., :3], [0.299, 0.587, 0.114])
                noise = np.repeat(noise_gray[:, :, np.newaxis], channels, axis=2)
            # å¦‚æœé¥±å’Œåº¦ä¸ä¸º0ï¼Œè°ƒæ•´å™ªå£°çš„è‰²å½©é¥±å’Œåº¦
            elif é¢—ç²’é¥±å’Œåº¦ != 1:
                # è®¡ç®—å™ªå£°çš„ç°åº¦ç‰ˆæœ¬
                noise_gray = np.dot(noise[..., :3], [0.299, 0.587, 0.114])
                noise_gray = np.repeat(noise_gray[:, :, np.newaxis], channels, axis=2)
                # æ’å€¼è°ƒæ•´é¥±å’Œåº¦
                noise = noise_gray + é¢—ç²’é¥±å’Œåº¦ * (noise - noise_gray)
            
            # åº”ç”¨é¢—ç²’å¼ºåº¦
            noise = noise * (é¢—ç²’å¼ºåº¦ / 10.0)
            
            # å°†å™ªå£°æ·»åŠ åˆ°åŸå§‹å›¾åƒ
            result = img + noise
            
            # ç¡®ä¿ç»“æœåœ¨[0, 1]èŒƒå›´å†…
            result = np.clip(result, 0, 1)
            
            # å°†å¤„ç†åçš„å›¾åƒæ·»åŠ åˆ°ç»“æœåˆ—è¡¨
            result_images.append(result)
        
        # å°†ç»“æœè½¬æ¢å›å¼ é‡
        result_tensor = torch.from_numpy(np.stack(result_images)).float()
        
        return (result_tensor,)

# èŠ‚ç‚¹æ˜ å°„ï¼Œç”¨äºåœ¨ComfyUIä¸­æ³¨å†ŒèŠ‚ç‚¹
NODE_CLASS_MAPPINGS = {
    "ğŸ‰Image-é¢—ç²’è´¨æ„Ÿ": Qwen_Image_Grain_Effect,
}

# èŠ‚ç‚¹æ˜¾ç¤ºåç§°æ˜ å°„
NODE_DISPLAY_NAME_MAPPINGS = {
    "ğŸ‰Image-é¢—ç²’è´¨æ„Ÿ": "ğŸ‰Image-é¢—ç²’è´¨æ„Ÿ-xishen",
}