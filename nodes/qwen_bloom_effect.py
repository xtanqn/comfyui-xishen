import torch
import numpy as np
from PIL import Image, ImageFilter
import torch.nn.functional as F

# å®šä¹‰æ³›å…‰æ•ˆæœèŠ‚ç‚¹ç±»
class ImageBloomEffect:
    """
    ğŸ­Image-æ³›å…‰æ•ˆæœèŠ‚ç‚¹
    æ ¸å¿ƒä½œç”¨ï¼šç»™å›¾åƒæ·»åŠ è¾‰å…‰æ•ˆæœï¼Œè®©å›¾åƒä¸­çš„é«˜å…‰åŒºåŸŸäº§ç”ŸæŸ”å’Œçš„æ‰©æ•£å‘å…‰ï¼Œå¢å¼ºç”»é¢çš„å…‰æ„Ÿã€æ¢¦å¹»æ„Ÿæˆ–çœŸå®æ„Ÿ
    """
    
    # è®¾ç½®èŠ‚ç‚¹åˆ†ç±»ï¼Œä½¿ç”¨ç»Ÿä¸€çš„é¡¹ç›®åˆ†ç±»
    CATEGORY = "ğŸ¡Comfyui-xishen"
    
    # å®šä¹‰è¾“å…¥å‚æ•°
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),  # å¾…å¤„ç†çš„åŸå§‹å›¾åƒï¼ˆå¿…å¡«ï¼‰
                "äº®åº¦ä¸‹é™": ("FLOAT", {
                    "default": 0.5,  # é»˜è®¤å€¼
                    "min": 0.0,       # æœ€å°å€¼
                    "max": 1.0,       # æœ€å¤§å€¼
                    "step": 0.1,      # è°ƒèŠ‚æ­¥é•¿æ”¹ä¸º0.1
                    "display": "slider"  # æ»‘å—æ˜¾ç¤º
                }),
                "äº®åº¦ä¸Šé™": ("FLOAT", {
                    "default": 1.0,   # é»˜è®¤å€¼
                    "min": 0.0,       # æœ€å°å€¼
                    "max": 1.0,       # æœ€å¤§å€¼
                    "step": 0.1,      # è°ƒèŠ‚æ­¥é•¿æ”¹ä¸º0.1
                    "display": "slider"  # æ»‘å—æ˜¾ç¤º
                }),
                "æ¨¡ç³Šç±»å‹": (["é«˜æ–¯æ¨¡ç³Š", "çŸ©å½¢", "å…‰æŸ"], {
                    "default": "é«˜æ–¯æ¨¡ç³Š"  # é»˜è®¤æ¨¡ç³Šç±»å‹
                }),
                "æ‰©æ•£èŒƒå›´": ("INT", {
                    "default": 15,     # é»˜è®¤å€¼
                    "min": 0,          # æœ€å°å€¼
                    "max": 50,         # æœ€å¤§å€¼
                    "step": 1,         # è°ƒèŠ‚æ­¥é•¿
                    "display": "slider"  # æ»‘å—æ˜¾ç¤º
                }),
                "é«˜å…‰äº®åº¦": ("FLOAT", {
                    "default": 1.0,    # é»˜è®¤å€¼
                    "min": 0.1,        # æœ€å°å€¼
                    "max": 50.0,       # æœ€å¤§å€¼
                    "step": 0.1,       # è°ƒèŠ‚æ­¥é•¿
                    "display": "slider"  # æ»‘å—æ˜¾ç¤º
                }),
                "æ··åˆæ–¹å¼": (["å±å¹•æ··åˆ", "ç›¸åŠ ", "ç›¸ä¹˜", "è¦†ç›–", "soft_light", "hard_light"], {
                    "default": "å±å¹•æ··åˆ"  # é»˜è®¤æ··åˆæ¨¡å¼
                }),
                "å¼ºåº¦è¡°å‡": ("FLOAT", {
                    "default": 0.5,    # é»˜è®¤å€¼
                    "min": 0.0,        # æœ€å°å€¼
                    "max": 1.0,        # æœ€å¤§å€¼
                    "step": 0.1,       # è°ƒèŠ‚æ­¥é•¿
                    "display": "slider"  # æ»‘å—æ˜¾ç¤º
                }),
                "åˆ†è¾¨ç‡ä¸Šé™": ("INT", {
                    "default": 2048,   # é»˜è®¤å€¼
                    "min": 256,        # æœ€å°å€¼
                    "max": 2048,       # æœ€å¤§å€¼ï¼ˆä¿®æ”¹ä¸º2048ï¼‰
                    "step": 256        # è°ƒèŠ‚æ­¥é•¿ï¼Œç§»é™¤æ»‘å—æ•ˆæœ
                }),
            },
            "optional": {
                "mask": ("MASK",),  # é®ç½©å›¾åƒï¼ˆå¯é€‰ï¼‰
            }
        }
    
    # å®šä¹‰è¾“å‡ºç±»å‹
    RETURN_TYPES = ("IMAGE", "IMAGE", "IMAGE", "MASK")
    RETURN_NAMES = ("modified_image", "highlights_image", "image", "mask")
    FUNCTION = "apply_bloom_effect"
    
    def apply_bloom_effect(self, image, äº®åº¦ä¸‹é™=0.5, äº®åº¦ä¸Šé™=1.0, æ¨¡ç³Šç±»å‹="é«˜æ–¯æ¨¡ç³Š", 
                          æ‰©æ•£èŒƒå›´=15, é«˜å…‰äº®åº¦=1.0, æ··åˆæ–¹å¼="å±å¹•æ··åˆ", 
                          å¼ºåº¦è¡°å‡=0.5, åˆ†è¾¨ç‡ä¸Šé™=2048, mask=None):
        """
        åº”ç”¨æ³›å…‰æ•ˆæœçš„æ ¸å¿ƒæ–¹æ³•
        
        å‚æ•°ï¼š
        - image: å¾…å¤„ç†çš„åŸå§‹å›¾åƒ
        - äº®åº¦ä¸‹é™: é«˜å…‰åŒºåŸŸçš„äº®åº¦ä¸‹é™
        - äº®åº¦ä¸Šé™: é«˜å…‰åŒºåŸŸçš„äº®åº¦ä¸Šé™
        - æ¨¡ç³Šç±»å‹: è¾‰å…‰çš„æ¨¡ç³Šç±»å‹
        - æ‰©æ•£èŒƒå›´: è¾‰å…‰çš„æ‰©æ•£èŒƒå›´
        - é«˜å…‰äº®åº¦: é«˜å…‰åŒºåŸŸçš„åŸºç¡€äº®åº¦
        - æ··åˆæ–¹å¼: è¾‰å…‰ä¸åŸå›¾çš„æ··åˆæ–¹å¼
        - å¼ºåº¦è¡°å‡: è¾‰å…‰çš„å¼ºåº¦è¡°å‡
        - åˆ†è¾¨ç‡ä¸Šé™: æ¨¡ç³Šå¤„ç†çš„åˆ†è¾¨ç‡ä¸Šé™
        - mask: é®ç½©å›¾åƒï¼ˆå¯é€‰ï¼‰
        
        è¿”å›ï¼š
        - modified_image: åº”ç”¨Bloomæ•ˆæœåçš„æœ€ç»ˆå›¾åƒ
        - highlights_image: æå–å‡ºçš„å›¾åƒé«˜å…‰åŒºåŸŸ
        - image: åŸå§‹å›¾åƒçš„ç›´é€šè¾“å‡º
        - mask: åŸå§‹é®ç½©çš„ç›´é€šè¾“å‡º
        """
        # å¤„ç†å›¾åƒå¼ é‡ï¼Œç¡®ä¿åœ¨CPUä¸Šæ“ä½œ
        if image.device.type == "cuda":
            image = image.cpu()
        
        # è½¬æ¢å›¾åƒæ ¼å¼ï¼šä»[0,1]èŒƒå›´çš„å¼ é‡è½¬æ¢ä¸ºPILå›¾åƒ
        image_np = image.numpy().squeeze(0)  # ç§»é™¤æ‰¹æ¬¡ç»´åº¦
        image_pil = Image.fromarray((image_np * 255).astype(np.uint8))
        
        # æå–å›¾åƒçš„äº®åº¦é€šé“ï¼ˆç”¨äºç¡®å®šé«˜å…‰åŒºåŸŸï¼‰
        image_gray = image_pil.convert("L")
        image_gray_np = np.array(image_gray) / 255.0
        
        # æ ¹æ®äº®åº¦ä¸Šä¸‹é™æå–é«˜å…‰åŒºåŸŸ
        # åˆ›å»ºé«˜å…‰æ©ç ï¼šäº®åº¦åœ¨[äº®åº¦ä¸‹é™, äº®åº¦ä¸Šé™]ä¹‹é—´çš„åƒç´ 
        highlights_mask = np.zeros_like(image_gray_np)
        highlights_mask[image_gray_np >= äº®åº¦ä¸‹é™] = 1.0
        
        # å¯¹é«˜å…‰æ©ç è¿›è¡Œæ¸å˜å¤„ç†ï¼Œä½¿è¾¹ç¼˜æ›´æŸ”å’Œ
        if äº®åº¦ä¸Šé™ > äº®åº¦ä¸‹é™:
            highlights_mask[np.logical_and(image_gray_np >= äº®åº¦ä¸‹é™, image_gray_np < äº®åº¦ä¸Šé™)] = \
                (image_gray_np[np.logical_and(image_gray_np >= äº®åº¦ä¸‹é™, image_gray_np < äº®åº¦ä¸Šé™)] - äº®åº¦ä¸‹é™) / (äº®åº¦ä¸Šé™ - äº®åº¦ä¸‹é™)
        
        # å°†é«˜å…‰æ©ç åº”ç”¨åˆ°åŸå§‹å›¾åƒï¼Œæå–é«˜å…‰åŒºåŸŸ
        highlights_np = image_np * highlights_mask[..., np.newaxis]
        
        # å¤„ç†é®ç½©ï¼ˆå¦‚æœæä¾›ï¼‰
        if mask is not None:
            if mask.device.type == "cuda":
                mask = mask.cpu()
            mask_np = mask.numpy().squeeze(0)  # ç§»é™¤æ‰¹æ¬¡ç»´åº¦
            # å°†é®ç½©åº”ç”¨åˆ°é«˜å…‰åŒºåŸŸ
            highlights_np = highlights_np * mask_np[..., np.newaxis]
        
        # è½¬æ¢é«˜å…‰åŒºåŸŸä¸ºPILå›¾åƒï¼Œç”¨äºåç»­æ¨¡ç³Šå¤„ç†
        highlights_pil = Image.fromarray((highlights_np * 255).astype(np.uint8))
        
        # æ ¹æ®åˆ†è¾¨ç‡ä¸Šé™è°ƒæ•´å›¾åƒå¤§å°ï¼Œä¼˜åŒ–æ€§èƒ½
        width, height = highlights_pil.size
        if width > åˆ†è¾¨ç‡ä¸Šé™ or height > åˆ†è¾¨ç‡ä¸Šé™:
            scale_factor = åˆ†è¾¨ç‡ä¸Šé™ / max(width, height)
            new_width = int(width * scale_factor)
            new_height = int(height * scale_factor)
            highlights_pil = highlights_pil.resize((new_width, new_height), Image.LANCZOS)
        
        # æ ¹æ®é€‰æ‹©çš„æ¨¡ç³Šç±»å‹è¿›è¡Œæ¨¡ç³Šå¤„ç†
        if æ¨¡ç³Šç±»å‹ == "é«˜æ–¯æ¨¡ç³Š":
            blurred_highlights = highlights_pil.filter(ImageFilter.GaussianBlur(radius=æ‰©æ•£èŒƒå›´))
        elif æ¨¡ç³Šç±»å‹ == "çŸ©å½¢":
            blurred_highlights = highlights_pil.filter(ImageFilter.BoxBlur(radius=æ‰©æ•£èŒƒå›´))
        elif æ¨¡ç³Šç±»å‹ == "å…‰æŸ":
            # å…‰æŸæ¨¡ç³Šæ•ˆæœï¼ˆé€šè¿‡å¤šæ¬¡é«˜æ–¯æ¨¡ç³Šæ¨¡æ‹Ÿï¼‰
            blurred_highlights = highlights_pil
            for i in range(3):
                blurred_highlights = blurred_highlights.filter(ImageFilter.GaussianBlur(radius=æ‰©æ•£èŒƒå›´ / (i + 1)))
        
        # æ¢å¤åŸå§‹å¤§å°ï¼ˆå¦‚æœä¹‹å‰è°ƒæ•´è¿‡ï¼‰
        if width > åˆ†è¾¨ç‡ä¸Šé™ or height > åˆ†è¾¨ç‡ä¸Šé™:
            blurred_highlights = blurred_highlights.resize((width, height), Image.LANCZOS)
        
        # è½¬æ¢æ¨¡ç³Šåçš„é«˜å…‰ä¸ºnumpyæ•°ç»„
        blurred_highlights_np = np.array(blurred_highlights) / 255.0
        
        # è°ƒæ•´é«˜å…‰äº®åº¦
        blurred_highlights_np = blurred_highlights_np * é«˜å…‰äº®åº¦
        
        # åº”ç”¨å¼ºåº¦è¡°å‡
        blurred_highlights_np = blurred_highlights_np * å¼ºåº¦è¡°å‡
        
        # å°†æ¨¡ç³Šåçš„é«˜å…‰ä¸åŸå§‹å›¾åƒæ··åˆ
        # è½¬æ¢åŸå§‹å›¾åƒä¸ºnumpyæ•°ç»„ï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
        original_image_np = np.array(image_pil) / 255.0
        
        # æ ¹æ®é€‰æ‹©çš„æ··åˆæ–¹å¼è¿›è¡Œæ··åˆ
        if æ··åˆæ–¹å¼ == "å±å¹•æ··åˆ":
            # å±å¹•æ··åˆï¼š1 - (1 - åŸå›¾) * (1 - è¾‰å…‰)
            modified_image_np = 1.0 - (1.0 - original_image_np) * (1.0 - blurred_highlights_np)
        elif æ··åˆæ–¹å¼ == "ç›¸åŠ ":
            # ç›¸åŠ æ··åˆï¼šåŸå›¾ + è¾‰å…‰
            modified_image_np = original_image_np + blurred_highlights_np
        elif æ··åˆæ–¹å¼ == "ç›¸ä¹˜":
            # ç›¸ä¹˜æ··åˆï¼šåŸå›¾ * è¾‰å…‰
            modified_image_np = original_image_np * (1.0 + blurred_highlights_np)
        elif æ··åˆæ–¹å¼ == "è¦†ç›–":
            # è¦†ç›–æ··åˆï¼šæ ¹æ®åŸå›¾äº®åº¦è°ƒæ•´æ··åˆæ–¹å¼
            modified_image_np = np.where(original_image_np <= 0.5, 2 * original_image_np * blurred_highlights_np, 1.0 - 2 * (1.0 - original_image_np) * (1.0 - blurred_highlights_np))
        elif æ··åˆæ–¹å¼ == "soft_light":
            # æŸ”å…‰æ··åˆï¼šç±»ä¼¼æŸ”å…‰æ•ˆæœ
            modified_image_np = np.where(blurred_highlights_np <= 0.5, original_image_np - (1.0 - 2.0 * blurred_highlights_np) * original_image_np * (1.0 - original_image_np), original_image_np + (2.0 * blurred_highlights_np - 1.0) * (np.sqrt(original_image_np) - original_image_np))
        elif æ··åˆæ–¹å¼ == "hard_light":
            # å¼ºå…‰æ··åˆï¼šç±»ä¼¼å¼ºå…‰æ•ˆæœ
            modified_image_np = np.where(blurred_highlights_np <= 0.5, 2 * original_image_np * blurred_highlights_np, 1.0 - 2 * (1.0 - original_image_np) * (1.0 - blurred_highlights_np))
        
        # ç¡®ä¿åƒç´ å€¼åœ¨[0, 1]èŒƒå›´å†…
        modified_image_np = np.clip(modified_image_np, 0.0, 1.0)
        
        # è½¬æ¢å›å¼ é‡æ ¼å¼
        modified_image = torch.from_numpy(modified_image_np).unsqueeze(0).float()
        highlights_image = torch.from_numpy(highlights_np).unsqueeze(0).float()
        
        # è¿”å›å¤„ç†ç»“æœå’Œç›´é€šè¾“å‡º
        return (modified_image, highlights_image, image, mask if mask is not None else torch.tensor([]))

# å®šä¹‰èŠ‚ç‚¹æ˜ å°„ï¼Œç”¨äºèŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "ğŸ­Image-æ³›å…‰æ•ˆæœ": ImageBloomEffect
}

# å®šä¹‰èŠ‚ç‚¹æ˜¾ç¤ºåç§°æ˜ å°„
NODE_DISPLAY_NAME_MAPPINGS = {
    "ğŸ­Image-æ³›å…‰æ•ˆæœ": "ğŸ­Image-æ³›å…‰æ•ˆæœ-xishen"
}